{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fd4064b",
   "metadata": {},
   "source": [
    "# 第8章PyTorch生态简介\n",
    "\n",
    "PyTorch不仅自身的易用性，更在于围绕PyTorch产生的一系列实用的工具包和程序，主要有：\n",
    "\n",
    "- torchvision  （图片）\n",
    "- pytorchvido  （视频）\n",
    "- torchtext   （文本）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb1083c",
   "metadata": {},
   "source": [
    "## 8.1 torchvision\n",
    "**torchvision的主要作用是**：提供主流的model，和常用数据集，以及提供transforms；\n",
    "\n",
    "**torchvision的主要的库是**：\n",
    "- torchvision.datasets*\n",
    "- torchvision.models*\n",
    "- torchvision.transforms*\n",
    "- torchvision.io\n",
    "- torchvision.ops\n",
    "- torchvision.utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52028425",
   "metadata": {},
   "source": [
    "### 8.1.1 torchvision.datasets\n",
    "torchvsion.datasets是用来进行数据加载的，PyTorch团队在这个包中帮我们提前处理好了很多很多图片数据集，有以下数据集：\n",
    "- MNISTCOCO\n",
    "- Captions\n",
    "- Detection\n",
    "- LSUN\n",
    "- ImageFolder\n",
    "- Imagenet-12\n",
    "- CIFAR\n",
    "- STL10\n",
    "- SVHN\n",
    "- PhotoTour\n",
    "......"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f02973",
   "metadata": {},
   "source": [
    "###  torchvision.datasets案例\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36443c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23728686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST数据集\n",
    "# 下载训练数据 train=False\n",
    "data_train = datasets.MNIST(\n",
    "    root = './data',# 表示MNIST数据加载的目录\n",
    "    train = True, # 表示是否加载数据库的训练集\n",
    "    download = True, # 表示如果root路径中无MNIST数据集，则将自动下载MNIST数据集\n",
    "    transform=None # 表示是否对数据进行预处理，None表示不进行预处理\n",
    ")\n",
    "# 下载测试数据 train=False\n",
    "data_test = datasets.MNIST(\n",
    "    root = './data',# 表示MNIST数据加载的目录\n",
    "    train = False, # 表示是否加载数据库的训练集\n",
    "    download = True, # 表示如果root路径中无MNIST数据集，则将自动下载MNIST数据集\n",
    "    transform=None # 表示是否对数据进行预处理，None表示不进行预处理\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7cc915",
   "metadata": {},
   "source": [
    "### 8.1.4 torchvision.models\n",
    "`torchvision.models` 中为我们提供了已经训练好的模型，让我们可以加载之后，直接使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85df5492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "# 快速创建一个权重随机初始化的模型\n",
    "resnet18 = models.resnet18()\n",
    "alexnet = models.alexnet()\n",
    "# 通过pretrained=True来加载一个别人预训练好的模型\n",
    "resnet18_pr = models.resnet18(pretrained=True)\n",
    "alexnet_pr = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6d74a0",
   "metadata": {},
   "source": [
    "### 8.1.3 torchvision.transforms\n",
    "`torchvision.transforms`对获取的数据进行归一化、大小缩放、数据增强操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c4d914b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "3750\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "# 将MNIST中28*28图片变成56*56的torch.tensor的格式，并归一化\n",
    "# 图像处理步骤\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(56), # 缩放到56*56\n",
    "    transforms.ToTensor(), # 数据转换成tensor格式\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # 归一化处理\n",
    "])\n",
    "# transforms.Normalize解释\n",
    "# 前面的（0.5，0.5，0.5） 是 R G B 三个通道上的均值，\n",
    "# 后面(0.5, 0.5, 0.5)是三个通道的标准差，\n",
    "# Normalize对每个通道执行以下操作：image =（图像-平均值）/ std在您的情况下，参数mean，std分别以0.5和0.5的形式传递\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data/', \n",
    "    train=True, \n",
    "    transform=transform, \n",
    "    download=True)\n",
    " \n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=16,\n",
    "                          shuffle=True)\n",
    "print(len(train_dataset))\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f5b68d",
   "metadata": {},
   "source": [
    "### 8.1.4  torchvision.io\n",
    "`torchvision.io`提高了读取视频、图片和文件的IO操作，包括读取、写入、编解码处理等效率。\n",
    "### 8.1.5 torchvision.ops\n",
    "`torchvision.ops`计算机视觉的特定操作，包括但不仅限于NMS，RoIAlign（MASK R-CNN中应用的一种方法），RoIPool（Fast R-CNN中用到的一种方法）。\n",
    "[详细内容看这](https://pytorch.org/vision/stable/ops.html)\n",
    "### 8.1.6 torchvision.utils\n",
    "`torchvision.utils` 为我们提供了一些可视化的方法，可以帮助我们将若干张图片拼接在一起、可视化检测和分割的效果。\n",
    "[详细内容看这](https://pytorch.org/vision/stable/utils.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d50e01",
   "metadata": {},
   "source": [
    "## 8.2 PyTorchVideo\n",
    "- 简介：`PyTorchVideo` 是一个专注于视频理解工作的深度学习库，提供加速视频理解研究所需的可重用、模块化和高效的组件，使用PyTorch开发，支持不同的深度学习视频组件，如视频模型、视频数据集和视频特定转换。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bbb4b4",
   "metadata": {},
   "source": [
    "## 8.3 torchtext\n",
    "`torchtext`是PyTorch的自然语言处理（NLP）的工具包，可对文本进行预处理，例如截断补长、构建词表等操作。\n",
    "\n",
    "`torchtext`主要包含以下组成部分：\n",
    "- 数据管理工具：torchtext.data.functional、torchtext.data.utils\n",
    "- 数据集：torchtext.data.datasets\n",
    "- 词表工具：torchtext.vocab\n",
    "- 评测工作：torchtext.metrics\n",
    "\n",
    "**NLP常见的数据预处理工作**：\n",
    "1. `Load File`: 数据文件加载\n",
    "2. `Tokenization`：分词\n",
    "3. `Create Vocabulary`：创建字典\n",
    "4. `Indexify`: 将词与索引进行映射\n",
    "5. `Word Vectors`：创建或加载词向量\n",
    "6. `Padding or Fix Length`：按长度对文本进行补齐或截取\n",
    "7. `Dataset Splits`：划分数据集（如将数据集划分为训练集、验证集、测试集)\n",
    "8. `Batching and Iterators`：将数据集按固定大小划分成Batch\n",
    "\n",
    "**torchtext完成以上工作**：\n",
    "1. 使用 `torchtext.legacy.data.Field` 定义样本各个字段的处理流程（分词、数据预处理等）；\n",
    "2. 使用 `torchtext.legacy.data.Example` 将 `torchtext.legacy.data.Field` 处理成一条样本；\n",
    "3. 使用 `torchtext.utils.data.Dataset` 将 `torchtext.legacy.data.Example` 处理成数据集，也可对数据集进行划分等工作；\n",
    "4. 使用 `torchtext.legacy.data.Iterators` 将 `torchtext.legacy.data.Dataset` 按照 batch_size 组装成 Batch 供模型训练使用；\n",
    "5. 使用 `torchtext.vocab` 和 `torchtext.vocab.Vectors` 创建词典、词和索引的一一对应、下载或使用预训练的词向量等；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3670a89",
   "metadata": {},
   "source": [
    "### 8.3.1 torchtext.legacy.data.Field\n",
    "- Field 包含一写文本处理的通用参数的设置，同时还包含一个词典对象，可以把文本数据表示成数字类型，进而可以把文本表示成需要的tensor类型。\n",
    "\n",
    "- 参数：\n",
    "\n",
    "- `sequential`: 是否把数据表示成序列，如果是False, 不能使用分词 默认值: True；\n",
    "- `use_vocab`: 是否使用词典对象. 如果是False 数据的类型必须已经是数值类型. 默认值: True；\n",
    "- `fix_length`: 修改每条数据的长度为该值，不够的用pad_token补全. 默认值: None；\n",
    "- `tokenize`: 分词函数.是一个 function 类型的对象（如 string.cut 、jieba.cut 等），用于对字符串进行分词；\n",
    "- `batch_first`: 如果该属性的值取 True，则该字段返回的 Tensor 对象的第一维度是 batch 的大小；默认值: False；\n",
    "\n",
    "\n",
    "- init_token: 每一条数据的起始字符 默认值: None；\n",
    "- eos_token: 每条数据的结尾字符 默认值: None；\n",
    "- tensor_type: 把数据转换成的tensor类型 默认值: torch.LongTensor；\n",
    "- preprocessing:在分词之后和数值化之前使用的管道 默认值: None；\n",
    "- postprocessing: 数值化之后和转化成tensor之前使用的管道默认值: None；\n",
    "- lower: 是否把数据转化为小写 默认值: False；\n",
    "- include_lengths: 是否返回一个已经补全的最小batch的元组和和一个包含每条数据长度的列表 . 默认值: False；\n",
    "- pad_token: 用于补全的字符. 默认值: “”；\n",
    "- unk_token: 不存在词典里的字符. 默认值: “”；\n",
    "- pad_first: 是否补全第一个字符. 默认值: False；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b6220fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field,Example,TabularDataset,Iterator,BucketIterator\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.vocab import Vectors\n",
    "from torch.nn import init\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "870d08dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.data.example.Example'>\n",
      "[\"d'aww!\", 'he', 'matches', 'this', 'background', 'colour']\n",
      "0\n",
      "tensor([[10, 12, 17, 25,  6,  9,  1,  1,  1,  1],\n",
      "        [27,  8, 15, 19, 14, 18, 21, 24,  1,  1],\n",
      "        [13,  2, 11,  3, 16,  5,  4, 23, 20,  1],\n",
      "        [ 2, 26,  7, 22,  1,  1,  1,  1,  1,  1]])\n"
     ]
    }
   ],
   "source": [
    "# 1.数据\n",
    "corpus = [\"D'aww! He matches this background colour\",\n",
    "         \"Yo bitch Ja Rule is more succesful then\",\n",
    "         \"If you have a look back at the source\",\n",
    "         \"You will become successful\"]\n",
    "labels = [0,1,0,1]\n",
    "# 2.定义不同的Field\n",
    "TEXT = Field(sequential=True, lower=True, fix_length=10,tokenize=str.split,batch_first=True)\n",
    "LABEL = Field(sequential=False, use_vocab=False)\n",
    "# 创建Fiedld的List\n",
    "fields = [(\"comment\", TEXT),(\"label\",LABEL)]\n",
    "# 3.将数据转换为Example对象的列表\n",
    "examples = []\n",
    "for text,label in zip(corpus,labels):\n",
    "    example = Example.fromlist([text,label],fields=fields)\n",
    "    examples.append(example)\n",
    "print(type(examples[0]))\n",
    "print(examples[0].comment)\n",
    "print(examples[0].label)\n",
    "# 4.构建词表\n",
    "new_corpus = [example.comment for example in examples]\n",
    "TEXT.build_vocab(new_corpus)\n",
    "print(TEXT.process(new_corpus))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45abbc81",
   "metadata": {},
   "source": [
    "### 8.3.2 构建词向量\n",
    "\n",
    "- 最简单的方法，bulid_vocab()方法中传入用于构建词表的数据集\n",
    "\n",
    "- TEXT.build_vocab(train)\n",
    "\n",
    "\n",
    "\n",
    "- Vocab的API\n",
    "```python\n",
    "class torchtext.vocab.Vocab(\n",
    "    counter, max_size=None, min_freq=1, specials=['<pad>'], \n",
    "    vectors=None, unk_init=None, vectors_cache=None, specials_first=True\n",
    ")\n",
    "# 为TEXT字段创建词向量TEXT.build_vocab(data_set)\n",
    "```\n",
    "- 重要参数：\n",
    "1. `counter`：collections.Counter 类型的对象，用于保存数据（如：单词）的频率；\n",
    "2. `vectors`：预训练的词向量，可以是torch.vocab.Vectors类型，也可以是其他类型；\n",
    "3. `min_freq`: 最低频率限制，如果某个词频率比min_freq低，则不记录到词典；\n",
    "\n",
    "```python\n",
    "# 为 TEXT 字段创建词向量\n",
    "TEXT.build_vocab(data_set)\n",
    "# 加载数据后可以建立词典，建立词典的时候可以使用与训练的word vector\n",
    "# 使用的词向量是glove.6B.100d的词向量\n",
    "TEXT.build_vocab(train, vectors=\"glove.6B.100d\")\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3447c01a",
   "metadata": {},
   "source": [
    "**使用训练好的词向量**\n",
    "- Vocab.Vectors API\n",
    "```python\n",
    "class torchtext.vocab.Vectors(name, cache=None, url=None, unk_init=None, max_vectors=None)\n",
    "```\n",
    "- 重要参数：\n",
    "1. `name`：保存word vectors的文件；\n",
    "2. `catch`：word vectors文件的缓存目录，默认是.vector_cache；\n",
    "3. `url`： 如果缓存文件夹中不存在 word vectors文件，则去该url下载；\n",
    "4. `unk_init`：是一个function 类型的对象，用来初始化词典中不存在的词向量；默认是Tensor.zero_；\n",
    "5. `max_vecotrs`：int类型的数据，限制词典的大小；\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aab8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import Vectors\n",
    "import torch.nn as nn\n",
    "# 使用预训练词向量\n",
    "# 下词向量下载地址: 链接：https://pan.baidu.com/s/113N_OBF3jluDPP_lKGzaKQ 提取码：surf \n",
    "word_vectors = Vectors('sgns.target.word-word.dynwin5.thr10.neg5.dim300.iter5', cache='./vectors')\n",
    "TEXT.build_vocab(train,vectors=Vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626727ac",
   "metadata": {},
   "source": [
    "**在模型中指定Embedding层的权重**\n",
    "\n",
    "在使用预训练好的词向量时，我们需要在神经网络模型的Embedding层中明确地传递嵌入矩阵的初始权重。权重包含在词汇表的vectors属性中。以Pytorch搭建的Embedding层为例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d44d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过pytorch创建的Embedding层\n",
    "\n",
    "embedding = nn.Embedding(2000, 256)\n",
    "# 指定嵌入矩阵的初始权重\n",
    "weight_matrix = TEXT.vocab.vectors\n",
    "embedding.weight.data.copy_(weight_matrix)\n",
    "# 指定预训练权重的同时设定requires_grad=True\n",
    "# embeddings.weight = nn.Parameter(embeddings, requires_grad=True)\n",
    "\n",
    "\n",
    "# 加载预训练词向量\n",
    "# freeze：该参数是指预训练词向量是否参与继续训练，True表示不继续参与训练；\n",
    "embedding_layer = nn.Embedding.from_pretrained(word_vectors.vectors, freeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352728b5",
   "metadata": {},
   "source": [
    "### torchtext.metrics\n",
    "- NLP中部分任务的评测不是通过准确率等指标完成的，比如机器翻译任务常用BLEU (bilingual\n",
    "evaluation understudy) score来评价预测文本和标签文本之间的相似程度。torchtext中可以直接调用\n",
    "torchtext.data.metrics.bleu_score来快速实现BLEU，下面是一个官方文档中的一个例子：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89001bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8408964276313782"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "candidate_corpus = [['My', 'full', 'pytorch', 'test'], ['Another', 'Sentence']]\n",
    "references_corpus = [[['My', 'full', 'pytorch', 'test'], ['Completely',\n",
    "'Different']], [['No', 'Match']]]\n",
    "bleu_score(candidate_corpus, references_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb037ab",
   "metadata": {},
   "source": [
    "# 总结：\n",
    "- 本次任务，主要介绍了PyTorch生态在图像、视频、文本等领域中的发展，并介绍了相关工具包的使用。\n",
    "\n",
    "1. `torchvision`（图像）：`torchvision`主要提供在计算机视觉中常常用到的数据集、模型和图像处理操作。\n",
    "2. `PyTorchVideo`(视频）：`PyTorchVideo`主要基于PyTorch，提供Model Zoo，支持数据预处理和常见数据，采用模块化设计，支持多模态，优化移动端部署。\n",
    "3. t`orchtext`(文本)：`torchtext`是PyTorch的自然语言处理（NLP）的工具包，可对文本进行预处理，例如截断补长、构建词表等操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fb5b40",
   "metadata": {},
   "source": [
    "## 参考\n",
    "https://relph1119.github.io/my-team-learning/#/pytorch_learning35/task07\n",
    "\n",
    "https://blog.csdn.net/qq_33590958/article/details/102602029\n",
    "\n",
    "https://blog.csdn.net/xingghaoyuxitong/article/details/113177968\n",
    "\n",
    "https://blog.csdn.net/xjm850552586/article/details/109137914\n",
    "\n",
    "https://blog.csdn.net/dendi_hust/article/details/101221922?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0.pc_relevant_paycolumn_v3&spm=1001.2101.3001.4242.1&utm_relevant_index=3\n",
    "\n",
    "https://blog.csdn.net/u014514939/article/details/88834123?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_default&utm_relevant_index=2\n",
    "\n",
    "https://blog.csdn.net/bqw18744018044/article/details/109150802\n",
    "\n",
    "https://blog.csdn.net/nlpuser/article/details/83627709"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33438502",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
